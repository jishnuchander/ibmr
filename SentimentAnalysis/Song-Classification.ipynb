{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Aritist</th>\n",
       "      <th>tag</th>\n",
       "      <th>Song_txt_loc</th>\n",
       "      <th>Song_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAAAED128E0783FAB</td>\n",
       "      <td>It's About Time</td>\n",
       "      <td>Jamie Cullum</td>\n",
       "      <td>relax</td>\n",
       "      <td>./lyrics_new/jamiecullum_itsabouttime.txt</td>\n",
       "      <td>Walking down to the water's edgeWhere I have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>TRAACER128F4290F96</td>\n",
       "      <td>Setting Fire to Sleeping Giants</td>\n",
       "      <td>The Dillinger Escape Plan</td>\n",
       "      <td>energetic</td>\n",
       "      <td>./lyrics_new/dillingerescapeplan_settingfireto...</td>\n",
       "      <td>First off Let me say you look so tired... Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>TRAADVO128E07999E9</td>\n",
       "      <td>Oh God</td>\n",
       "      <td>Jamie Cullum</td>\n",
       "      <td>relax</td>\n",
       "      <td>./lyrics_new/jamiecullum_ohgod.txt</td>\n",
       "      <td>I know it's been a while since I have talked ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>TRAAFGQ128F427D884</td>\n",
       "      <td>One Last Time</td>\n",
       "      <td>The Kooks</td>\n",
       "      <td>sad</td>\n",
       "      <td>./lyrics_new/kooks_onelasttime.txt</td>\n",
       "      <td>Can I hold you one last time To fight the fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>TRAAGPJ128F428CD1B</td>\n",
       "      <td>I Never Came</td>\n",
       "      <td>Queens Of The Stone Age</td>\n",
       "      <td>sad</td>\n",
       "      <td>./lyrics_new/queensofthestoneage_inevercame.txt</td>\n",
       "      <td>When you say it's dead &amp;amp; gone Yes, I know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                  id                             Name  \\\n",
       "0           0      0  TRAAAED128E0783FAB                  It's About Time   \n",
       "1           1      3  TRAACER128F4290F96  Setting Fire to Sleeping Giants   \n",
       "2           2      7  TRAADVO128E07999E9                           Oh God   \n",
       "3           3      8  TRAAFGQ128F427D884                    One Last Time   \n",
       "4           4     13  TRAAGPJ128F428CD1B                     I Never Came   \n",
       "\n",
       "                     Aritist        tag  \\\n",
       "0               Jamie Cullum      relax   \n",
       "1  The Dillinger Escape Plan  energetic   \n",
       "2               Jamie Cullum      relax   \n",
       "3                  The Kooks        sad   \n",
       "4    Queens Of The Stone Age        sad   \n",
       "\n",
       "                                        Song_txt_loc  \\\n",
       "0          ./lyrics_new/jamiecullum_itsabouttime.txt   \n",
       "1  ./lyrics_new/dillingerescapeplan_settingfireto...   \n",
       "2                 ./lyrics_new/jamiecullum_ohgod.txt   \n",
       "3                 ./lyrics_new/kooks_onelasttime.txt   \n",
       "4    ./lyrics_new/queensofthestoneage_inevercame.txt   \n",
       "\n",
       "                                         Song_lyrics  \n",
       "0   Walking down to the water's edgeWhere I have ...  \n",
       "1   First off Let me say you look so tired... Res...  \n",
       "2   I know it's been a while since I have talked ...  \n",
       "3   Can I hold you one last time To fight the fee...  \n",
       "4   When you say it's dead &amp; gone Yes, I know...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"full_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "love         5458\n",
       "party        1630\n",
       "sad          1304\n",
       "emotional    1274\n",
       "happy        1123\n",
       "grunge       1034\n",
       "memory        904\n",
       "religious     892\n",
       "dark          765\n",
       "relax         531\n",
       "political     511\n",
       "energetic     506\n",
       "christmas     474\n",
       "funny         470\n",
       "freedom       286\n",
       "halloween     121\n",
       "rain           81\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_tags = ['christmans', 'dark', 'emotional', 'relax', 'freedom', 'funny', 'grunge', 'halloween',\n",
    "           'happy', 'love', 'memory', 'party', 'political', 'rain', 'energetic', 'religious', 'sad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of words: 3852628\n"
     ]
    }
   ],
   "source": [
    "print('No of words:', df['Song_lyrics'].apply(lambda x: len(x.split(' '))).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I know it's been a while since I have talked to youBut maybe you're the one who makes the winds blowWe're looking at the stars without explanationWe contemplate as kings and simple men on trialOur little world's fragile\\nOh God can you tell us when it's going to stopMaybe it's not just down to youOh God can we win back what we have lostSo who's the last resort... Oh God\\nTumbling towards unclear destinationsDo they wash away the blame,The wind and the searing rainsAs our powers interchange\\nOh God can you tell us when it's going to stopMaybe it's not just down to youOh God can we win back what we have lost  Oh God can you tell us when it's going to stopMaybe it's not just down to youOh God can we win back what we have lostSo who's the last resort\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Song_lyrics'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I know it's been a while since I have talked to youBut maybe you're the one who makes the winds blowWe're looking at the stars without explanationWe contemplate as kings and simple men on trialOur little world's fragile Oh God can you tell us when it's going to stopMaybe it's not just down to youOh God can we win back what we have lostSo who's the last resort... Oh God Tumbling towards unclear destinationsDo they wash away the blame,The wind and the searing rainsAs our powers interchange Oh God can you tell us when it's going to stopMaybe it's not just down to youOh God can we win back what we have lost  Oh God can you tell us when it's going to stopMaybe it's not just down to youOh God can we win back what we have lostSo who's the last resort\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace('\\n',' ', regex=True)\n",
    "df['Song_lyrics'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    Cleaning lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jishnu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "df['lyrics_without_stopwords'] = df['Song_lyrics'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "df['lyrics_clean'] = df['lyrics_without_stopwords'].apply(lambda s: s.translate(str.maketrans('', '', string.punctuation)))\n",
    "df['lyrics_clean'] = df['lyrics_clean'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics_clean</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>walking waters edgewhere i beforeif i find lov...</td>\n",
       "      <td>relax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>first let say look tired rest head shut eyes e...</td>\n",
       "      <td>energetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i know since i talked youbut maybe one makes w...</td>\n",
       "      <td>relax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>can i hold one last time to fight feeling grow...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>when say dead amp gone yes i know wrong cut am...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17359</td>\n",
       "      <td>this shall pass oh always comes backand knocki...</td>\n",
       "      <td>religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17360</td>\n",
       "      <td>he lord he reigns high he lord spoke darkness ...</td>\n",
       "      <td>religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17361</td>\n",
       "      <td>exception occurred list index range</td>\n",
       "      <td>religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17362</td>\n",
       "      <td>heres plani think i got madelife easywhen sitt...</td>\n",
       "      <td>religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17363</td>\n",
       "      <td>its piece paper says in god we trusta little s...</td>\n",
       "      <td>religious</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17364 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            lyrics_clean        tag\n",
       "0      walking waters edgewhere i beforeif i find lov...      relax\n",
       "1      first let say look tired rest head shut eyes e...  energetic\n",
       "2      i know since i talked youbut maybe one makes w...      relax\n",
       "3      can i hold one last time to fight feeling grow...        sad\n",
       "4      when say dead amp gone yes i know wrong cut am...        sad\n",
       "...                                                  ...        ...\n",
       "17359  this shall pass oh always comes backand knocki...  religious\n",
       "17360  he lord he reigns high he lord spoke darkness ...  religious\n",
       "17361                exception occurred list index range  religious\n",
       "17362  heres plani think i got madelife easywhen sitt...  religious\n",
       "17363  its piece paper says in god we trusta little s...  religious\n",
       "\n",
       "[17364 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[['lyrics_clean', 'tag']]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of words: 2354865\n"
     ]
    }
   ],
   "source": [
    "print('No of words:', df1['lyrics_clean'].apply(lambda x: len(x.split(' '))).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = df1.lyrics_clean\n",
    "y = df1.tag\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.31362763915547026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  christmans       0.00      0.00      0.00       154\n",
      "        dark       0.00      0.00      0.00       224\n",
      "   emotional       0.00      0.00      0.00       388\n",
      "       relax       0.00      0.00      0.00       161\n",
      "     freedom       0.00      0.00      0.00        89\n",
      "       funny       0.00      0.00      0.00       136\n",
      "      grunge       0.00      0.00      0.00       303\n",
      "   halloween       0.00      0.00      0.00        32\n",
      "       happy       0.00      0.00      0.00       323\n",
      "        love       0.31      1.00      0.48      1632\n",
      "      memory       0.00      0.00      0.00       257\n",
      "       party       1.00      0.00      0.01       519\n",
      "   political       0.00      0.00      0.00       157\n",
      "        rain       0.00      0.00      0.00        22\n",
      "   energetic       0.00      0.00      0.00       156\n",
      "   religious       0.00      0.00      0.00       256\n",
      "         sad       0.00      0.00      0.00       401\n",
      "\n",
      "    accuracy                           0.31      5210\n",
      "   macro avg       0.08      0.06      0.03      5210\n",
      "weighted avg       0.20      0.31      0.15      5210\n",
      "\n",
      "CPU times: user 648 ms, sys: 0 ns, total: 648 ms\n",
      "Wall time: 646 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jishnu/.local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=5, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=42,\n",
       "                               shuffle=True, tol=None, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVM\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4295585412667946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  christmans       0.67      0.81      0.73       154\n",
      "        dark       0.40      0.31      0.35       224\n",
      "   emotional       0.37      0.20      0.26       388\n",
      "       relax       0.15      0.04      0.06       161\n",
      "     freedom       0.48      0.13      0.21        89\n",
      "       funny       0.48      0.24      0.32       136\n",
      "      grunge       0.42      0.26      0.32       303\n",
      "   halloween       0.80      0.38      0.51        32\n",
      "       happy       0.13      0.04      0.07       323\n",
      "        love       0.45      0.82      0.59      1632\n",
      "      memory       0.19      0.18      0.18       257\n",
      "       party       0.50      0.38      0.43       519\n",
      "   political       0.48      0.38      0.43       157\n",
      "        rain       0.56      0.23      0.32        22\n",
      "   energetic       0.10      0.02      0.03       156\n",
      "   religious       0.43      0.52      0.47       256\n",
      "         sad       0.18      0.06      0.09       401\n",
      "\n",
      "    accuracy                           0.43      5210\n",
      "   macro avg       0.40      0.29      0.32      5210\n",
      "weighted avg       0.38      0.43      0.38      5210\n",
      "\n",
      "CPU times: user 642 ms, sys: 0 ns, total: 642 ms\n",
      "Wall time: 641 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jishnu/.local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jishnu/.local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=1, penalty='l2',\n",
       "                                    random_state=None, solver='warn',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logstic Regression \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.43550863723608446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  christmans       0.87      0.72      0.79       154\n",
      "        dark       0.45      0.38      0.41       224\n",
      "   emotional       0.35      0.28      0.31       388\n",
      "       relax       0.09      0.04      0.06       161\n",
      "     freedom       0.47      0.21      0.29        89\n",
      "       funny       0.35      0.38      0.36       136\n",
      "      grunge       0.37      0.28      0.32       303\n",
      "   halloween       0.78      0.44      0.56        32\n",
      "       happy       0.13      0.10      0.11       323\n",
      "        love       0.52      0.69      0.59      1632\n",
      "      memory       0.38      0.35      0.36       257\n",
      "       party       0.52      0.53      0.53       519\n",
      "   political       0.53      0.34      0.42       157\n",
      "        rain       0.64      0.41      0.50        22\n",
      "   energetic       0.04      0.03      0.03       156\n",
      "   religious       0.51      0.49      0.50       256\n",
      "         sad       0.17      0.18      0.17       401\n",
      "\n",
      "    accuracy                           0.44      5210\n",
      "   macro avg       0.42      0.34      0.37      5210\n",
      "weighted avg       0.42      0.44      0.42      5210\n",
      "\n",
      "CPU times: user 921 ms, sys: 72.7 ms, total: 994 ms\n",
      "Wall time: 855 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 54s, sys: 2.06 s, total: 6min 56s\n",
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', RandomForestClassifier(n_estimators=500 ,random_state=0)),\n",
    "               ])\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.46775431861804223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  christmans       0.97      0.68      0.80       154\n",
      "        dark       0.87      0.29      0.44       224\n",
      "   emotional       0.93      0.16      0.28       388\n",
      "       relax       0.67      0.02      0.05       161\n",
      "     freedom       0.89      0.19      0.31        89\n",
      "       funny       0.66      0.27      0.39       136\n",
      "      grunge       0.97      0.19      0.32       303\n",
      "   halloween       1.00      0.44      0.61        32\n",
      "       happy       0.86      0.02      0.04       323\n",
      "        love       0.38      0.99      0.54      1632\n",
      "      memory       0.97      0.33      0.49       257\n",
      "       party       0.90      0.46      0.61       519\n",
      "   political       0.95      0.22      0.36       157\n",
      "        rain       1.00      0.27      0.43        22\n",
      "   energetic       0.25      0.01      0.01       156\n",
      "   religious       0.85      0.32      0.47       256\n",
      "         sad       0.88      0.02      0.03       401\n",
      "\n",
      "    accuracy                           0.47      5210\n",
      "   macro avg       0.82      0.29      0.36      5210\n",
      "weighted avg       0.71      0.47      0.40      5210\n",
      "\n",
      "CPU times: user 3.26 s, sys: 0 ns, total: 3.26 s\n",
      "Wall time: 3.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "christmans  :  0.6753246753246753\n",
      "dark  :  0.29464285714285715\n",
      "emotional  :  0.16494845360824742\n",
      "relax  :  0.024844720496894408\n",
      "freedom  :  0.19101123595505617\n",
      "funny  :  0.27205882352941174\n",
      "grunge  :  0.19141914191419143\n",
      "halloween  :  0.4375\n",
      "happy  :  0.018575851393188854\n",
      "love  :  0.9865196078431373\n",
      "memory  :  0.33073929961089493\n",
      "party  :  0.464354527938343\n",
      "political  :  0.2229299363057325\n",
      "rain  :  0.2727272727272727\n",
      "energetic  :  0.00641025641025641\n",
      "religious  :  0.3203125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "for i in range(16):\n",
    "    print(my_tags[i], ' : ', accuracies[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4288\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if(y_pred[i]=='love'):\n",
    "        ctr+=1\n",
    "\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5210"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of lists\n",
    "\n",
    "lyrics = df1['lyrics_clean'].values.tolist()\n",
    "sentences = [line.split() for line in lyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre trained word embeddings\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True, limit=200000)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vectorizer(sentence):\n",
    "    words = sentence.split()\n",
    "    mean = np.mean([wv[word] for word in words if word in wv.vocab] or [np.zeros(300,)], axis=0)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [sentence_vectorizer(sentence) for sentence in X] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jishnu/.local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jishnu/.local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.9 s, sys: 31.4 ms, total: 39.9 s\n",
      "Wall time: 39.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.3802303262955854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  christmans       0.69      0.69      0.69       154\n",
      "        dark       0.29      0.20      0.23       224\n",
      "   emotional       0.23      0.09      0.13       388\n",
      "       relax       0.06      0.01      0.02       161\n",
      "     freedom       0.15      0.06      0.08        89\n",
      "       funny       0.28      0.18      0.22       136\n",
      "      grunge       0.26      0.15      0.19       303\n",
      "   halloween       0.15      0.16      0.15        32\n",
      "       happy       0.10      0.02      0.04       323\n",
      "        love       0.41      0.83      0.55      1632\n",
      "      memory       0.22      0.04      0.07       257\n",
      "       party       0.40      0.32      0.36       519\n",
      "   political       0.39      0.27      0.32       157\n",
      "        rain       0.08      0.18      0.11        22\n",
      "   energetic       0.10      0.01      0.02       156\n",
      "   religious       0.46      0.41      0.43       256\n",
      "         sad       0.14      0.04      0.06       401\n",
      "\n",
      "    accuracy                           0.38      5210\n",
      "   macro avg       0.26      0.22      0.22      5210\n",
      "weighted avg       0.31      0.38      0.31      5210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred, target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec embeddings \n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences, min_count=5, size=50, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('leave', 0.6968371272087097),\n",
       " ('lonely', 0.683151364326477),\n",
       " ('youleave', 0.6151683926582336),\n",
       " ('afraid', 0.6015790700912476),\n",
       " ('wondering', 0.6000429391860962)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('alone')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vectorizer2(sentence):\n",
    "    words = sentence.split()\n",
    "    mean = np.mean([model[word] for word in words if word in model.wv.vocab] or [np.zeros(100,)], axis=0)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train_data = [sentence_vectorizer2(sentence) for sentence in X] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jishnu/.local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/jishnu/.local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.04 s, sys: 15.7 ms, total: 6.06 s\n",
      "Wall time: 6.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.36238003838771593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  christmans       0.77      0.62      0.69       154\n",
      "        dark       0.22      0.08      0.11       224\n",
      "   emotional       0.09      0.01      0.01       388\n",
      "       relax       0.00      0.00      0.00       161\n",
      "     freedom       0.00      0.00      0.00        89\n",
      "       funny       0.21      0.04      0.06       136\n",
      "      grunge       0.23      0.07      0.11       303\n",
      "   halloween       0.00      0.00      0.00        32\n",
      "       happy       0.07      0.00      0.01       323\n",
      "        love       0.36      0.93      0.52      1632\n",
      "      memory       0.00      0.00      0.00       257\n",
      "       party       0.38      0.23      0.29       519\n",
      "   political       0.23      0.11      0.15       157\n",
      "        rain       0.50      0.05      0.08        22\n",
      "   energetic       0.00      0.00      0.00       156\n",
      "   religious       0.50      0.33      0.40       256\n",
      "         sad       0.17      0.01      0.02       401\n",
      "\n",
      "    accuracy                           0.36      5210\n",
      "   macro avg       0.22      0.15      0.14      5210\n",
      "weighted avg       0.26      0.36      0.25      5210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jishnu/.local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred, target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=500 ,random_state=0)\n",
    "rfc = rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.47715930902111325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  christmans       0.84      0.62      0.72       154\n",
      "        dark       0.62      0.38      0.47       224\n",
      "   emotional       0.92      0.17      0.28       388\n",
      "       relax       0.67      0.02      0.05       161\n",
      "     freedom       0.94      0.19      0.32        89\n",
      "       funny       0.95      0.26      0.40       136\n",
      "      grunge       0.84      0.20      0.32       303\n",
      "   halloween       1.00      0.44      0.61        32\n",
      "       happy       0.53      0.02      0.05       323\n",
      "        love       0.40      0.97      0.56      1632\n",
      "      memory       0.93      0.33      0.49       257\n",
      "       party       0.67      0.55      0.60       519\n",
      "   political       0.69      0.31      0.42       157\n",
      "        rain       1.00      0.27      0.43        22\n",
      "   energetic       0.33      0.01      0.01       156\n",
      "   religious       0.75      0.33      0.46       256\n",
      "         sad       0.57      0.02      0.04       401\n",
      "\n",
      "    accuracy                           0.48      5210\n",
      "   macro avg       0.74      0.30      0.37      5210\n",
      "weighted avg       0.62      0.48      0.41      5210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred, target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "christmans  :  0.6233766233766234\n",
      "dark  :  0.38392857142857145\n",
      "emotional  :  0.16752577319587628\n",
      "relax  :  0.024844720496894408\n",
      "freedom  :  0.19101123595505617\n",
      "funny  :  0.25735294117647056\n",
      "grunge  :  0.20132013201320131\n",
      "halloween  :  0.4375\n",
      "happy  :  0.02476780185758514\n",
      "love  :  0.9681372549019608\n",
      "memory  :  0.33073929961089493\n",
      "party  :  0.5529865125240848\n",
      "political  :  0.3057324840764331\n",
      "rain  :  0.2727272727272727\n",
      "energetic  :  0.00641025641025641\n",
      "religious  :  0.33203125\n",
      "sad  :  0.0199501246882793\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "for i in range(17):\n",
    "    print(my_tags[i], ' : ', accuracies[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3994\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if(y_pred[i]=='love'):\n",
    "        ctr+=1\n",
    "\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.327984"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('joy', 'happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lucky', 0.6671848893165588),\n",
       " ('valentines', 0.581880509853363),\n",
       " ('lovely', 0.5433056950569153),\n",
       " ('someday', 0.5305999517440796),\n",
       " ('suspected', 0.5217271447181702)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('happy')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
